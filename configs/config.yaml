agent:
  type: causal
  name: HuggingFaceTB/SmolLM2-135M
  device: cpu

experts:
  num_experts: 3

lora:
  enabled: true
  r: 16
  lora_alpha: 32
  lora_dropout: 0.1
  target_modules: ["q_proj", "v_proj"]

training:
  output_dir: "./results"
  evaluation_strategy: "steps"
  save_strategy: "no"
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 4
  eval_accumulation_steps: 4
  eval_steps: 250
  max_steps: 5
  logging_steps: 50
  learning_rate: 1e-4
  weight_decay: 0.01

data:
  data_cache_dir: "./data/cache"
  category: "summarization"
  name: "samsum"
  split: ["train[:10%]+validation[:5%]+test[:5%]"]